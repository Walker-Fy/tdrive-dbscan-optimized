{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial-exploration",
   "metadata": {},
   "source": [
    "# T-Drive出租车轨迹数据探索分析\n",
    "\n",
    "本笔记本用于探索和分析T-Drive出租车轨迹数据集，为后续的DBSCAN聚类算法提供数据理解和预处理基础。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environment-setup",
   "metadata": {},
   "source": [
    "## 1. 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-libraries",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# 添加项目根目录到Python路径\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# 导入所需库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置中文字体和图表样式\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Python版本:\", sys.version)\n",
    "print(\"NumPy版本:\", np.__version__)\n",
    "print(\"Pandas版本:\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loader",
   "metadata": {},
   "source": [
    "## 2. 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data-modules",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入项目中的数据处理模块\n",
    "from src.data_processing.loader import TDriveDataLoader, load_tdrive_csv\n",
    "from src.data_processing.preprocessor import TrajectoryPreprocessor\n",
    "from src.data_processing.trajectory import Trajectory, TrajectoryPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configure-data-path",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置数据路径\n",
    "data_path = \"../data/raw\"  # 根据实际情况调整\n",
    "\n",
    "# 创建数据加载器\n",
    "loader = TDriveDataLoader(data_path, max_workers=2)\n",
    "\n",
    "# 检查数据文件\n",
    "import glob\n",
    "csv_files = glob.glob(f\"{data_path}/*.csv\")\n",
    "if not csv_files:\n",
    "    csv_files = glob.glob(f\"{data_path}/*.txt\")\n",
    "    \n",
    "print(f\"找到 {len(csv_files)} 个数据文件:\")\n",
    "for file in csv_files[:5]:  # 显示前5个文件\n",
    "    print(f\"  {os.path.basename(file)}\")\n",
    "if len(csv_files) > 5:\n",
    "    print(f\"  ... 还有 {len(csv_files) - 5} 个文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-sample-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载单个文件进行初步分析\n",
    "sample_file = csv_files[0] if csv_files else None\n",
    "\n",
    "if sample_file:\n",
    "    print(f\"加载样本文件: {os.path.basename(sample_file)}\")\n",
    "    \n",
    "    # 使用DataFrame加载少量数据进行探索\n",
    "    df_sample = load_tdrive_csv(sample_file, nrows=10000)\n",
    "    print(f\"加载了 {len(df_sample)} 行数据\")\n",
    "    print(\"\\n数据预览:\")\n",
    "    display(df_sample.head(10))\n",
    "    \n",
    "    print(\"\\n数据信息:\")\n",
    "    df_sample.info()\n",
    "    \n",
    "    print(\"\\n数据统计描述:\")\n",
    "    display(df_sample.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-quality",
   "metadata": {},
   "source": [
    "## 3. 数据质量分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-missing-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查缺失值\n",
    "if 'df_sample' in locals():\n",
    "    print(\"缺失值统计:\")\n",
    "    missing_stats = df_sample.isnull().sum()\n",
    "    missing_percent = (missing_stats / len(df_sample)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        '缺失数量': missing_stats,\n",
    "        '缺失比例(%)': missing_percent.round(2)\n",
    "    })\n",
    "    display(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-duplicates",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查重复数据\n",
    "if 'df_sample' in locals():\n",
    "    duplicates = df_sample.duplicated().sum()\n",
    "    print(f\"重复行数: {duplicates} ({duplicates/len(df_sample)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check-unique-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查唯一值\n",
    "if 'df_sample' in locals():\n",
    "    print(\"唯一值统计:\")\n",
    "    unique_stats = {\n",
    "        '出租车ID数量': df_sample['taxi_id'].nunique(),\n",
    "        '时间戳唯一值': df_sample['timestamp'].nunique(),\n",
    "        '纬度唯一值': df_sample['lat'].nunique(),\n",
    "        '经度唯一值': df_sample['lon'].nunique()\n",
    "    }\n",
    "    \n",
    "    for key, value in unique_stats.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-analysis",
   "metadata": {},
   "source": [
    "## 4. 空间分布分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-spatial-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制空间分布图\n",
    "if 'df_sample' in locals():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # 散点图\n",
    "    ax1 = axes[0]\n",
    "    scatter = ax1.scatter(df_sample['lon'], df_sample['lat'], \n",
    "                         c=range(len(df_sample)), cmap='viridis',\n",
    "                         s=10, alpha=0.6, edgecolors='none')\n",
    "    ax1.set_xlabel('经度')\n",
    "    ax1.set_ylabel('纬度')\n",
    "    ax1.set_title('轨迹点空间分布')\n",
    "    plt.colorbar(scatter, ax=ax1, label='点序号')\n",
    "    \n",
    "    # 六边形箱图（热力图）\n",
    "    ax2 = axes[1]\n",
    "    hb = ax2.hexbin(df_sample['lon'], df_sample['lat'], \n",
    "                   gridsize=30, cmap='YlOrRd', alpha=0.8)\n",
    "    ax2.set_xlabel('经度')\n",
    "    ax2.set_ylabel('纬度')\n",
    "    ax2.set_title('轨迹点密度热力图')\n",
    "    plt.colorbar(hb, ax=ax2, label='点数')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beijing-bounds-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查数据是否在北京范围内\n",
    "if 'df_sample' in locals():\n",
    "    # 北京的大致边界坐标\n",
    "    beijing_bounds = {\n",
    "        'min_lat': 39.4,  # 南边界\n",
    "        'max_lat': 40.6,  # 北边界\n",
    "        'min_lon': 115.7,  # 西边界\n",
    "        'max_lon': 117.4   # 东边界\n",
    "    }\n",
    "    \n",
    "    # 计算在边界内的点比例\n",
    "    in_beijing = (\n",
    "        (df_sample['lat'] >= beijing_bounds['min_lat']) & \n",
    "        (df_sample['lat'] <= beijing_bounds['max_lat']) &\n",
    "        (df_sample['lon'] >= beijing_bounds['min_lon']) & \n",
    "        (df_sample['lon'] <= beijing_bounds['max_lon'])\n",
    "    )\n",
    "    \n",
    "    in_beijing_percent = in_beijing.mean() * 100\n",
    "    \n",
    "    print(f\"在北京范围内的点: {in_beijing.sum()} ({in_beijing_percent:.2f}%)\")\n",
    "    print(f\"不在北京范围内的点: {(~in_beijing).sum()} ({(100 - in_beijing_percent):.2f}%)\")\n",
    "    \n",
    "    # 绘制边界检查\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # 绘制所有点\n",
    "    ax.scatter(df_sample['lon'], df_sample['lat'], \n",
    "              c=in_beijing.map({True: 'blue', False: 'red'}),\n",
    "              s=10, alpha=0.6, edgecolors='none')\n",
    "    \n",
    "    # 绘制北京边界\n",
    "    from matplotlib.patches import Rectangle\n",
    "    rect = Rectangle((beijing_bounds['min_lon'], beijing_bounds['min_lat']),\n",
    "                     beijing_bounds['max_lon'] - beijing_bounds['min_lon'],\n",
    "                     beijing_bounds['max_lat'] - beijing_bounds['min_lat'],\n",
    "                     fill=False, edgecolor='green', linewidth=2, linestyle='--',\n",
    "                     label='北京边界')\n",
    "    ax.add_patch(rect)\n",
    "    \n",
    "    ax.set_xlabel('经度')\n",
    "    ax.set_ylabel('纬度')\n",
    "    ax.set_title('北京边界检查 (蓝色: 边界内, 红色: 边界外)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "temporal-analysis",
   "metadata": {},
   "source": [
    "## 5. 时间特征分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-temporal-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取时间特征\n",
    "if 'df_sample' in locals():\n",
    "    # 确保时间戳列是datetime类型\n",
    "    df_sample['timestamp'] = pd.to_datetime(df_sample['timestamp'])\n",
    "    \n",
    "    # 提取时间特征\n",
    "    df_sample['hour'] = df_sample['timestamp'].dt.hour\n",
    "    df_sample['day'] = df_sample['timestamp'].dt.day\n",
    "    df_sample['month'] = df_sample['timestamp'].dt.month\n",
    "    df_sample['weekday'] = df_sample['timestamp'].dt.weekday  # 0=周一, 6=周日\n",
    "    \n",
    "    print(\"时间特征提取完成\")\n",
    "    display(df_sample[['timestamp', 'hour', 'day', 'month', 'weekday']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-temporal-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制时间分布\n",
    "if 'df_sample' in locals():\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # 小时分布\n",
    "    ax1 = axes[0, 0]\n",
    "    hour_counts = df_sample['hour'].value_counts().sort_index()\n",
    "    ax1.bar(hour_counts.index, hour_counts.values, color='skyblue', alpha=0.7)\n",
    "    ax1.set_xlabel('小时')\n",
    "    ax1.set_ylabel('点数')\n",
    "    ax1.set_title('按小时分布')\n",
    "    ax1.set_xticks(range(0, 24, 2))\n",
    "    \n",
    "    # 星期分布\n",
    "    ax2 = axes[0, 1]\n",
    "    weekday_names = ['周一', '周二', '周三', '周四', '周五', '周六', '周日']\n",
    "    weekday_counts = df_sample['weekday'].value_counts().sort_index()\n",
    "    ax2.bar(weekday_counts.index, weekday_counts.values, \n",
    "           color='lightgreen', alpha=0.7, tick_label=weekday_names)\n",
    "    ax2.set_xlabel('星期')\n",
    "    ax2.set_ylabel('点数')\n",
    "    ax2.set_title('按星期分布')\n",
    "    \n",
    "    # 日分布\n",
    "    ax3 = axes[1, 0]\n",
    "    day_counts = df_sample['day'].value_counts().sort_index()\n",
    "    ax3.plot(day_counts.index, day_counts.values, 'o-', color='salmon', alpha=0.7)\n",
    "    ax3.set_xlabel('日')\n",
    "    ax3.set_ylabel('点数')\n",
    "    ax3.set_title('按日分布')\n",
    "    \n",
    "    # 月分布\n",
    "    ax4 = axes[1, 1]\n",
    "    month_counts = df_sample['month'].value_counts().sort_index()\n",
    "    ax4.bar(month_counts.index, month_counts.values, color='gold', alpha=0.7)\n",
    "    ax4.set_xlabel('月')\n",
    "    ax4.set_ylabel('点数')\n",
    "    ax4.set_title('按月分布')\n",
    "    ax4.set_xticks(range(1, 13))\n",
    "    \n",
    "    plt.suptitle('轨迹点时间分布分析', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taxi-analysis",
   "metadata": {},
   "source": [
    "## 6. 出租车个体分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taxi-activity-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析出租车活动\n",
    "if 'df_sample' in locals():\n",
    "    # 出租车活动统计\n",
    "    taxi_stats = df_sample.groupby('taxi_id').agg({\n",
    "        'timestamp': ['count', 'min', 'max'],\n",
    "        'lat': ['mean', 'std'],\n",
    "        'lon': ['mean', 'std']\n",
    "    }).round(4)\n",
    "    \n",
    "    taxi_stats.columns = ['点数', '最早时间', '最晚时间', \n",
    "                         '平均纬度', '纬度标准差', '平均经度', '经度标准差']\n",
    "    \n",
    "    print(f\"出租车数量: {len(taxi_stats)}\")\n",
    "    print(\"\\n出租车活动统计:\")\n",
    "    display(taxi_stats.describe())\n",
    "    \n",
    "# 绘制出租车活动分布\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # 点数分布\n",
    "    ax1 = axes[0]\n",
    "    taxi_counts = taxi_stats['点数'].sort_values()\n",
    "    ax1.hist(taxi_counts, bins=30, color='skyblue', alpha=0.7, edgecolor='black')\n",
    "    ax1.set_xlabel('每个出租车的点数')\n",
    "    ax1.set_ylabel('出租车数量')\n",
    "    ax1.set_title('出租车活动量分布')\n",
    "    ax1.axvline(taxi_counts.mean(), color='red', linestyle='--', \n",
    "                label=f'均值: {taxi_counts.mean():.1f}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 累积分布\n",
    "    ax2 = axes[1]\n",
    "    taxi_counts_sorted = taxi_counts.sort_values(ascending=False).reset_index(drop=True)\n",
    "    cumulative_percent = (taxi_counts_sorted.cumsum() / taxi_counts_sorted.sum()) * 100\n",
    "    \n",
    "    ax2.plot(range(1, len(cumulative_percent) + 1), cumulative_percent, \n",
    "             color='green', linewidth=2)\n",
    "    ax2.set_xlabel('出租车排名')\n",
    "    ax2.set_ylabel('累积活动量占比 (%)')\n",
    "    ax2.set_title('出租车活动量累积分布')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 标记关键点\n",
    "    for percent in [20, 50, 80]:\n",
    "        idx = np.argmax(cumulative_percent >= percent)\n",
    "        ax2.scatter(idx + 1, cumulative_percent[idx], color='red', s=50)\n",
    "        ax2.text(idx + 1, cumulative_percent[idx] + 2, \n",
    "                f'{percent}%: 前{idx + 1}辆出租车', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trajectory-processing",
   "metadata": {},
   "source": [
    "## 7. 轨迹数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-trajectories",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载完整轨迹数据\n",
    "print(\"加载轨迹数据（采样率: 0.5%）...\")\n",
    "\n",
    "try:\n",
    "    # 使用项目的数据加载器加载轨迹\n",
    "    trajectories = loader.load_all_trajectories(\n",
    "        sample_rate=0.005,  # 0.5% 采样率\n",
    "        limit_per_file=50   # 每个文件最多50条轨迹\n",
    "    )\n",
    "    \n",
    "    print(f\"成功加载 {len(trajectories)} 条轨迹\")\n",
    "    \n",
    "    # 显示第一条轨迹的信息\n",
    "    if trajectories:\n",
    "        first_traj = trajectories[0]\n",
    "        print(f\"\\n第一条轨迹信息:\")\n",
    "        print(f\"  出租车ID: {first_traj.taxi_id}\")\n",
    "        print(f\"  点数: {len(first_traj.points)}\")\n",
    "        print(f\"  开始时间: {first_traj.start_time}\")\n",
    "        print(f\"  结束时间: {first_traj.end_time}\")\n",
    "        print(f\"  持续时间: {first_traj.duration/3600:.2f} 小时\")\n",
    "        print(f\"  总距离: {first_traj.total_distance/1000:.2f} km\")\n",
    "        print(f\"  平均速度: {first_traj.avg_speed*3.6:.2f} km/h\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"加载轨迹数据时出错: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess-trajectories",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理轨迹数据\n",
    "if 'trajectories' in locals() and trajectories:\n",
    "    print(\"\\n预处理轨迹数据...\")\n",
    "    \n",
    "    preprocessor = TrajectoryPreprocessor(\n",
    "        min_trajectory_length=10,\n",
    "        max_speed_kmh=120.0,\n",
    "        sampling_interval_s=60.0,\n",
    "        remove_outliers=True\n",
    "    )\n",
    "    \n",
    "    processed_trajectories = preprocessor.preprocess_trajectories(trajectories)\n",
    "    print(f\"预处理后保留 {len(processed_trajectories)} 条轨迹 \"\n",
    "          f\"({len(processed_trajectories)/len(trajectories)*100:.1f}%)\")\n",
    "    \n",
    "    # 显示预处理前后的对比\n",
    "    if processed_trajectories:\n",
    "        processed_traj = processed_trajectories[0]\n",
    "        print(f\"\\n预处理后的第一条轨迹信息:\")\n",
    "        print(f\"  点数: {len(processed_traj.points)}\")\n",
    "        print(f\"  持续时间: {processed_traj.duration/3600:.2f} 小时\")\n",
    "        print(f\"  总距离: {processed_traj.total_distance/1000:.2f} km\")\n",
    "        print(f\"  平均速度: {processed_traj.avg_speed*3.6:.2f} km/h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize-trajectories",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化轨迹\n",
    "if 'processed_trajectories' in locals() and processed_trajectories:\n",
    "    # 选择前10条轨迹进行可视化\n",
    "    trajectories_to_plot = processed_trajectories[:10]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "    \n",
    "    # 1. 所有轨迹叠加图\n",
    "    ax1 = axes[0, 0]\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(trajectories_to_plot)))\n",
    "    \n",
    "    for i, traj in enumerate(trajectories_to_plot):\n",
    "        points_array = traj.to_points_array()\n",
    "        if len(points_array) > 1:\n",
    "            ax1.plot(points_array[:, 1], points_array[:, 0], \n",
    "                    color=colors[i], alpha=0.7, linewidth=1, \n",
    "                    label=f'Taxi {traj.taxi_id[:8]}')\n",
    "    \n",
    "    ax1.set_xlabel('经度')\n",
    "    ax1.set_ylabel('纬度')\n",
    "    ax1.set_title('出租车轨迹叠加图')\n",
    "    ax1.legend(loc='upper right', fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. 轨迹点密度图\n",
    "    ax2 = axes[0, 1]\n",
    "    all_points = []\n",
    "    for traj in trajectories_to_plot:\n",
    "        points_array = traj.to_points_array()\n",
    "        all_points.extend(points_array.tolist())\n",
    "    \n",
    "    all_points = np.array(all_points)\n",
    "    if len(all_points) > 0:\n",
    "        hb = ax2.hexbin(all_points[:, 1], all_points[:, 0], \n",
    "                       gridsize=30, cmap='YlOrRd', alpha=0.8)\n",
    "        ax2.set_xlabel('经度')\n",
    "        ax2.set_ylabel('纬度')\n",
    "        ax2.set_title('轨迹点密度热力图')\n",
    "        plt.colorbar(hb, ax=ax2, label='点数')\n",
    "    \n",
    "    # 3. 轨迹长度分布\n",
    "    ax3 = axes[1, 0]\n",
    "    distances = [traj.total_distance/1000 for traj in trajectories_to_plot]  # km\n",
    "    durations = [traj.duration/3600 for traj in trajectories_to_plot]  # hours\n",
    "    \n",
    "    scatter = ax3.scatter(durations, distances, c=range(len(trajectories_to_plot)), \n",
    "                         cmap='viridis', s=100, alpha=0.7, edgecolors='black')\n",
    "    ax3.set_xlabel('持续时间 (小时)')\n",
    "    ax3.set_ylabel('总距离 (km)')\n",
    "    ax3.set_title('轨迹长度与持续时间关系')\n",
    "    plt.colorbar(scatter, ax=ax3, label='轨迹序号')\n",
    "    \n",
    "    # 添加平均速度线\n",
    "    speeds = [dist/dur if dur > 0 else 0 for dist, dur in zip(distances, durations)]\n",
    "    avg_speed = np.mean([s for s in speeds if s > 0])\n",
    "    \n",
    "    x_max = max(durations) * 1.1\n",
    "    y_line = avg_speed * x_max\n",
    "    ax3.plot([0, x_max], [0, y_line], 'r--', alpha=0.5, \n",
    "            label=f'平均速度: {avg_speed:.1f} km/h')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # 4. 轨迹速度分布\n",
    "    ax4 = axes[1, 1]\n",
    "    avg_speeds = []\n",
    "    max_speeds = []\n",
    "    \n",
    "    for traj in trajectories_to_plot:\n",
    "        if hasattr(traj, 'avg_speed') and traj.avg_speed:\n",
    "            avg_speeds.append(traj.avg_speed * 3.6)  # 转换为km/h\n",
    "            max_speeds.append(traj.max_speed * 3.6)  # 转换为km/h\n",
    "    \n",
    "    if avg_speeds:\n",
    "        x_pos = range(len(avg_speeds))\n",
    "        width = 0.35\n",
    "        \n",
    "        ax4.bar([p - width/2 for p in x_pos], avg_speeds, width, \n",
    "               color='skyblue', alpha=0.7, label='平均速度')\n",
    "        ax4.bar([p + width/2 for p in x_pos], max_speeds, width, \n",
    "               color='salmon', alpha=0.7, label='最大速度')\n",
    "        \n",
    "        ax4.set_xlabel('轨迹序号')\n",
    "        ax4.set_ylabel('速度 (km/h)')\n",
    "        ax4.set_title('轨迹速度分布')\n",
    "        ax4.set_xticks(x_pos)\n",
    "        ax4.set_xticklabels([f'T{i+1}' for i in x_pos])\n",
    "        ax4.legend()\n",
    "    \n",
    "    plt.suptitle('出租车轨迹分析', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-analysis",
   "metadata": {},
   "source": [
    "## 8. 数据探索总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成数据探索总结\n",
    "print(\"数据探索分析总结\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "summary = {}\n",
    "\n",
    "if 'df_sample' in locals():\n",
    "    summary[\"样本数据\"] = {\n",
    "        \"总行数\": len(df_sample),\n",
    "        \"出租车数量\": df_sample['taxi_id'].nunique(),\n",
    "        \"时间范围\": f\"{df_sample['timestamp'].min()} 到 {df_sample['timestamp'].max()}\",\n",
    "        \"纬度范围\": f\"{df_sample['lat'].min():.4f} 到 {df_sample['lat'].max():.4f}\",\n",
    "        \"经度范围\": f\"{df_sample['lon'].min():.4f} 到 {df_sample['lon'].max():.4f}\",\n",
    "        \"缺失值比例\": f\"{df_sample.isnull().sum().sum() / (len(df_sample) * len(df_sample.columns)) * 100:.2f}%\"\n",
    "    }\n",
    "\n",
    "if 'trajectories' in locals():\n",
    "    summary[\"轨迹数据\"] = {\n",
    "        \"轨迹数量\": len(trajectories),\n",
    "        \"平均轨迹长度\": f\"{np.mean([len(t.points) for t in trajectories]):.1f} 点\",\n",
    "        \"平均持续时间\": f\"{np.mean([t.duration for t in trajectories])/3600:.2f} 小时\",\n",
    "        \"平均距离\": f\"{np.mean([t.total_distance for t in trajectories])/1000:.2f} km\"\n",
    "    }\n",
    "\n",
    "if 'processed_trajectories' in locals():\n",
    "    summary[\"预处理后轨迹\"] = {\n",
    "        \"保留轨迹比例\": f\"{len(processed_trajectories)/len(trajectories)*100:.1f}%\",\n",
    "        \"平均速度\": f\"{np.mean([t.avg_speed*3.6 for t in processed_trajectories]):.1f} km/h\",\n",
    "        \"最大速度\": f\"{np.max([t.max_speed*3.6 for t in processed_trajectories]):.1f} km/h\"\n",
    "    }\n",
    "\n",
    "# 打印总结\n",
    "for category, stats in summary.items():\n",
    "    print(f\"\\n{category}:\")\n",
    "    print(\"-\" * 40)\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clustering-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为聚类准备数据\n",
    "print(\"\\n聚类数据准备:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if 'processed_trajectories' in locals() and processed_trajectories:\n",
    "    # 提取所有轨迹点\n",
    "    all_points = []\n",
    "    for traj in processed_trajectories:\n",
    "        for point in traj.points:\n",
    "            all_points.append([point.latitude, point.longitude])\n",
    "    \n",
    "    points_array = np.array(all_points)\n",
    "    \n",
    "    print(f\"总点数: {len(points_array)}\")\n",
    "    print(f\"数据形状: {points_array.shape}\")\n",
    "    print(f\"纬度范围: [{points_array[:, 0].min():.4f}, {points_array[:, 0].max():.4f}]\")\n",
    "    print(f\"经度范围: [{points_array[:, 1].min():.4f}, {points_array[:, 1].max():.4f}]\")\n",
    "    \n",
    "    # 计算点密度\n",
    "    lat_range = points_array[:, 0].max() - points_array[:, 0].min()\n",
    "    lon_range = points_array[:, 1].max() - points_array[:, 1].min()\n",
    "    area = lat_range * lon_range\n",
    "    density = len(points_array) / area if area > 0 else 0\n",
    "    \n",
    "    print(f\"空间面积: {area:.6f} 度²\")\n",
    "    print(f\"点密度: {density:.1f} 点/度²\")\n",
    "    \n",
    "    # 保存为聚类数据\n",
    "    clustering_data_path = \"../data/processed/clustering_points.npy\"\n",
    "    os.makedirs(os.path.dirname(clustering_data_path), exist_ok=True)\n",
    "    np.save(clustering_data_path, points_array)\n",
    "    print(f\"\\n聚类数据已保存到: {clustering_data_path}\")\n",
    "else:\n",
    "    print(\"没有可用的预处理轨迹数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "## 9. 结论与建议"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion-content",
   "metadata": {},
   "source": [
    "### 关键发现\n",
    "\n",
    "1. **数据质量**: 数据基本完整，缺失值较少，但有部分点在北京范围外，需要过滤\n",
    "2. **空间分布**: 轨迹点集中在北京城区，有明显的热点区域\n",
    "3. **时间特征**: 有明显的早晚高峰模式，工作日与周末模式不同\n",
    "4. **出租车活动**: 不同出租车的活动量差异较大，少数出租车贡献了大部分数据\n",
    "5. **轨迹特征**: 轨迹长度、持续时间和速度分布符合实际交通模式\n",
    "\n",
    "### 对DBSCAN聚类的建议\n",
    "\n",
    "1. **参数选择**:\n",
    "   - eps: 建议在0.001-0.01之间进行测试\n",
    "   - min_samples: 建议在5-15之间，根据点密度调整\n",
    "   \n",
    "2. **预处理策略**:\n",
    "   - 过滤北京范围外的点\n",
    "   - 去除异常速度的点\n",
    "   - 对超长轨迹进行分段\n",
    "   \n",
    "3. **性能优化**:\n",
    "   - 考虑使用空间索引加速邻域查询\n",
    "   - 对于大规模数据，采用分批处理策略\n",
    "   - 利用多核CPU进行并行计算\n",
    "\n",
    "4. **聚类目标**:\n",
    "   - 识别热点区域（如商业区、交通枢纽）\n",
    "   - 发现出租车活动模式\n",
    "   - 分析时空聚类特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e7f959",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdrive-dbscan-optimized",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
